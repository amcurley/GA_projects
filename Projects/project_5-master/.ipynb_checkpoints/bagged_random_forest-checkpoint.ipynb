{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-31T13:13:52.249678Z",
     "iopub.status.busy": "2020-08-31T13:13:52.249455Z",
     "iopub.status.idle": "2020-08-31T13:13:52.322870Z",
     "shell.execute_reply": "2020-08-31T13:13:52.322502Z",
     "shell.execute_reply.started": "2020-08-31T13:13:52.249653Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotly'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-c1dbbe01a67f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpress\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_objects\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'plotly'"
     ]
    }
   ],
   "source": [
    "# Patrick's amazing code\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier, GradientBoostingClassifier, RandomForestClassifier, VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.metrics import confusion_matrix, metrics, mean_squared_error, f1_score\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, LassoCV, RidgeCV\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures, PowerTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', 2000)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating all of our different classification models\n",
    "lr_class = LogisticRegression(penalty='l1', C=40, solver='liblinear')\n",
    "knn_class = KNeighborsClassifier(n_neighbors=3, p=4, leaf_size=10)\n",
    "tree_class = DecisionTreeClassifier(max_features='auto', min_samples_leaf=3, min_samples_split=4, random_state=42)\n",
    "bag_class = BaggingClassifier(bootstrap=False, max_features=8, max_samples=100, max_samples=100, n_estimators=100, random_state=42)\n",
    "forest_class = RandomForestClassifier(bootstrap=True, max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=8, n_estimators=100, random_state=42)\n",
    "ada_class = AdaBoostClassifier(learning_rate=0.78, n_estimators=100, random_state=42)\n",
    "svc = SVC(degree=8, C=1, gamma=1, kernel='rbf', random_state=100)\n",
    "grad_class = GradientBoostingClassifier(n_estimators=100, min_samples_leaf=3, min_samples_split=8, max_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_models = {\n",
    "    'lr_class': lr_class,\n",
    "    'forest_class': forest_class,\n",
    "    'tree_class': tree_class,\n",
    "    'ada_class': ada_class,\n",
    "    'knn_class': knn_class,\n",
    "    'bag_class': bag_class,\n",
    "    'svc': svc,\n",
    "    'grad': grad_class\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_testc = []\n",
    "y_pred_trainc = []\n",
    "\n",
    "for model in class_models.values():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred_testc.append(model.predict(X_test))\n",
    "    y_pred_trainc.append(model.predict(X_train))\n",
    "    \n",
    "y_pred_testc_df = pd.DataFrame(y_pred_testc, index=class_models.keys()).T\n",
    "y_pred_trainc_df = pd.DataFrame(y_pred_trainc, index=class_models.keys()).T\n",
    "print(y_pred_testc_df.shape)\n",
    "print(y_pred_trainc_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = {'train': [], \n",
    "            'test': [], \n",
    "            'F1-train': [], \n",
    "            'F1-test': [], \n",
    "            'true_neg': [], \n",
    "            'fal_pos': [],\n",
    "            'fal_neg': [], \n",
    "            'true_pos': [], \n",
    "           }\n",
    "for model in class_models.values():\n",
    "    accuracy['train'].append(model.score(X_train, y_train))\n",
    "    accuracy['test'].append(model.score(X_test, y_test))\n",
    "for col in y_pred_testc_df:\n",
    "    accuracy['F1-train'].append(f1_score(y_train, y_pred_trainc_df[col]))\n",
    "    accuracy['F1-test'].append(f1_score(y_test, y_pred_testc_df[col]))\n",
    "for col in y_pred_testc_df:\n",
    "    accuracy['true_neg'].append(confusion_matrix(y_test, y_pred_testc_df[col])[0][0])\n",
    "    accuracy['fal_pos'].append(confusion_matrix(y_test, y_pred_testc_df[col])[0][1])\n",
    "    accuracy['fal_neg'].append(confusion_matrix(y_test, y_pred_testc_df[col])[1][0])\n",
    "    accuracy['true_pos'].append(confusion_matrix(y_test, y_pred_testc_df[col])[1][1])\n",
    "accuracy_df = df.DataFrame(accuracy, index=class_models.keys())\n",
    "accuracy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master = test_master_agg[features]\n",
    "master_sc = ss.fit_transform(master)\n",
    "predicted_player = pd.DataFrame(index=master.index)\n",
    "predicted_player[['Player_name','DRAFT_YEAR+1']] = test_master_agg[['Player_name','DRAFT_YEAR+1']]\n",
    "for (model_name, model) in class_models.items():\n",
    "    predicted_player[model_name] = model.predict(master_sc)\n",
    "predicted_player['tot'] = predicted_player['lr_class'] + predicted_player['forest_class'] + predicted_player['tree_class']\n",
    "# predicted_player.to_csv('predict_15_16_17_based_on_2nd_yr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store predicted_player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_player.sort_values(by='tot', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'max_depth' : [3,4],\n",
    "    'min_samples_leaf' : [2,3],\n",
    "    'min_samples_split' : [6,7,8],\n",
    "    'n_estimators' : [30, 35, 37],\n",
    "    'learning_rate' : (np.logspace(-1.6, -1, 20))\n",
    "    'C' : np.logspace(-3,3,7),\n",
    "    'gamma' : np.logspace(-3,3,7)\n",
    "}\n",
    "gs = GridSearchCV(\n",
    "    SVC(),\n",
    "    params,\n",
    "    cv=3,\n",
    "    verbose=1,\n",
    "    return_train_score=False,\n",
    "    n_jobs=2)\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_score_)\n",
    "print()\n",
    "print(gs.best_params_)\n",
    "print()\n",
    "print(gs.score(X_test, y_test))\n",
    "pred  model.predict(X_test)\n",
    "f1_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        ''' Recall metric.\n",
    "        \n",
    "        Only computes a batch_wise average of recall.\n",
    "        \n",
    "        Computes the recall, a metric for multi-label classification of \n",
    "        how many relevant items are selected.\n",
    "        '''\n",
    "        true_positives = K.sum(K.round(K.clip(y_true, 0,1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "    \n",
    "    def precision(y_true, y_pred):\n",
    "        '''Precision metric.\n",
    "        \n",
    "        Only computes a batch-wise average of precision.\n",
    "        \n",
    "        Computes the precision, a metric for multi-label classification of \n",
    "        how many selected items are relevant.\n",
    "        '''\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0,1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0,1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
