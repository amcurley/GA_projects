{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://api.pushshift.io/reddit/search/submission'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Machine Learning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a question mark after the submission and do subreddit=subredditname\n",
    "# https://api.pushshift.io/reddit/search/submission?subreddit=MachineLearning\n",
    "\n",
    "params_ml = {\n",
    "    'subreddit': 'MachineLearning',\n",
    "    'size': 500,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_ml = requests.get(url, params_ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_ml.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ml = res_ml.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_ml = data_ml['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(posts_ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_df = pd.DataFrame(posts_ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml = ml_df[['subreddit', 'title', 'selftext']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>Market Research for our startup product. It is...</td>\n",
       "      <td>[removed]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         subreddit                                              title  \\\n",
       "0  MachineLearning  Market Research for our startup product. It is...   \n",
       "\n",
       "    selftext  \n",
       "0  [removed]  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Artificial Inteligence**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_ai = {\n",
    "    'subreddit': 'ArtificialInteligence',\n",
    "    'size': 100\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_ai = requests.get(url, params_ai)\n",
    "# res_ai.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ai = res_ai.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_ai = data_ai['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1597549757"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_ai[0]['created_utc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(posts_ai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_df = pd.DataFrame(posts_ai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai = ai_df[['subreddit', 'title', 'selftext']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ArtificialInteligence</td>\n",
       "      <td>OUR TIME is COMING! Have a Wonderful and Produ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               subreddit                                              title  \\\n",
       "0  ArtificialInteligence  OUR TIME is COMING! Have a Wonderful and Produ...   \n",
       "\n",
       "  selftext  \n",
       "0           "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ArtificialInteligence</td>\n",
       "      <td>OUR TIME is COMING! Have a Wonderful and Produ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               subreddit                                              title  \\\n",
       "0  ArtificialInteligence  OUR TIME is COMING! Have a Wonderful and Produ...   \n",
       "\n",
       "  selftext  \n",
       "0           "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the last UTC code for the first 100 pulls for r/ArtificalIntelligence\n",
    "type(posts_ai[-1]['created_utc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1597278469"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_ai[-1]['created_utc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subreddit(sub1, sub2):\n",
    "#     utc_codes_ai = []\n",
    "#     utc_codes_ml = []\n",
    "\n",
    "    params_ai = {\n",
    "    'subreddit': sub1,\n",
    "    'size': 100,\n",
    "#     'before': 30d\n",
    "    }\n",
    "\n",
    "    # ML\n",
    "    params_ml = {\n",
    "        'subreddit': sub2,\n",
    "        'size': 100,\n",
    "    }\n",
    "\n",
    "#   Get Url & Paramters\n",
    "    # AI\n",
    "    res_ai = requests.get(url, params_ai)\n",
    "    # ML\n",
    "    res_ml = requests.get(url, params_ml)\n",
    "\n",
    "#   Get the data from res\n",
    "    # AI\n",
    "    data_ai = res_ai.json()\n",
    "    # ML\n",
    "    data_ml = res_ml.json()\n",
    "\n",
    "#   Get the posts from data\n",
    "    # AI\n",
    "    posts_ai = data_ai['data']\n",
    "    # ML\n",
    "    posts_ml = data_ml['data']\n",
    "\n",
    "#   Append UTC code to list\n",
    "#     utc_codes_ai.append(posts_ai[-1]['created_utc'])\n",
    "\n",
    "#   Create post dataframe\n",
    "    # AI\n",
    "    ai_df = pd.DataFrame(posts_ai)\n",
    "    # ML\n",
    "    ml_df = pd.DataFrame(posts_ml)\n",
    "\n",
    "#   New Dataframe with only features we need\n",
    "    # AI\n",
    "    ai = ai_df[['subreddit', 'title', 'selftext']]\n",
    "    # ML\n",
    "    ml = ml_df[['subreddit', 'title', 'selftext']]\n",
    "    \n",
    "#     for n in posts_ai:\n",
    "#         utc = posts_ai[-1]['created_utc']\n",
    "#         utc_codes_ai.append(utc)\n",
    "\n",
    "    return ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ArtificialInteligence</td>\n",
       "      <td>OUR TIME is COMING! Have a Wonderful and Produ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ArtificialInteligence</td>\n",
       "      <td>It's in the circuitry . No way to stop it</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ArtificialInteligence</td>\n",
       "      <td>Are you interested in machine learning? Experi...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ArtificialInteligence</td>\n",
       "      <td>I entered \"I believe artificial intelligence\" ...</td>\n",
       "      <td>I believe that artificial intelligence is the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ArtificialInteligence</td>\n",
       "      <td>A weapon to fight back</td>\n",
       "      <td>A weapon to fight back\\n\\nElon musk and neural...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ArtificialInteligence</td>\n",
       "      <td>Transforming Data Assets to Technology Unravel...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>ArtificialInteligence</td>\n",
       "      <td>Artificial Intelligence Development Company in...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>ArtificialInteligence</td>\n",
       "      <td>Do you know how AI is healing custom healthcar...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>ArtificialInteligence</td>\n",
       "      <td>What's the Difference Between AI, Machine Lear...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ArtificialInteligence</td>\n",
       "      <td>AI Surgical Robots are Taking Over Hospitals</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                subreddit                                              title  \\\n",
       "0   ArtificialInteligence  OUR TIME is COMING! Have a Wonderful and Produ...   \n",
       "1   ArtificialInteligence          It's in the circuitry . No way to stop it   \n",
       "2   ArtificialInteligence  Are you interested in machine learning? Experi...   \n",
       "3   ArtificialInteligence  I entered \"I believe artificial intelligence\" ...   \n",
       "4   ArtificialInteligence                             A weapon to fight back   \n",
       "..                    ...                                                ...   \n",
       "95  ArtificialInteligence  Transforming Data Assets to Technology Unravel...   \n",
       "96  ArtificialInteligence  Artificial Intelligence Development Company in...   \n",
       "97  ArtificialInteligence  Do you know how AI is healing custom healthcar...   \n",
       "98  ArtificialInteligence  What's the Difference Between AI, Machine Lear...   \n",
       "99  ArtificialInteligence       AI Surgical Robots are Taking Over Hospitals   \n",
       "\n",
       "                                             selftext  \n",
       "0                                                      \n",
       "1                                                      \n",
       "2                                                      \n",
       "3   I believe that artificial intelligence is the ...  \n",
       "4   A weapon to fight back\\n\\nElon musk and neural...  \n",
       "..                                                ...  \n",
       "95                                                     \n",
       "96                                                     \n",
       "97                                                     \n",
       "98                                                     \n",
       "99                                                     \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subreddit('ArtificialInteligence', 'MachineLearning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_ml = ai.append(ml).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ArtificialInteligence</td>\n",
       "      <td>OUR TIME is COMING! Have a Wonderful and Produ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ArtificialInteligence</td>\n",
       "      <td>It's in the circuitry . No way to stop it</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ArtificialInteligence</td>\n",
       "      <td>Are you interested in machine learning? Experi...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ArtificialInteligence</td>\n",
       "      <td>I entered \"I believe artificial intelligence\" ...</td>\n",
       "      <td>I believe that artificial intelligence is the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ArtificialInteligence</td>\n",
       "      <td>A weapon to fight back</td>\n",
       "      <td>A weapon to fight back\\n\\nElon musk and neural...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>95</td>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>https://www.youtube.com/watch?v=rt7-qmemNDk</td>\n",
       "      <td>[removed]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>96</td>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>[D] This is exactly the kind of misogyny that ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>97</td>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>[D] Hi everyone, check out my article here: ht...</td>\n",
       "      <td>Hi everyone,\\n\\ncheck out my article here: [ht...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>98</td>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>Understanding differences between Drake’s old ...</td>\n",
       "      <td>[removed]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>99</td>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>[D] Is it worth signing up for interviewquery ...</td>\n",
       "      <td>[removed]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index              subreddit  \\\n",
       "0        0  ArtificialInteligence   \n",
       "1        1  ArtificialInteligence   \n",
       "2        2  ArtificialInteligence   \n",
       "3        3  ArtificialInteligence   \n",
       "4        4  ArtificialInteligence   \n",
       "..     ...                    ...   \n",
       "195     95        MachineLearning   \n",
       "196     96        MachineLearning   \n",
       "197     97        MachineLearning   \n",
       "198     98        MachineLearning   \n",
       "199     99        MachineLearning   \n",
       "\n",
       "                                                 title  \\\n",
       "0    OUR TIME is COMING! Have a Wonderful and Produ...   \n",
       "1            It's in the circuitry . No way to stop it   \n",
       "2    Are you interested in machine learning? Experi...   \n",
       "3    I entered \"I believe artificial intelligence\" ...   \n",
       "4                               A weapon to fight back   \n",
       "..                                                 ...   \n",
       "195        https://www.youtube.com/watch?v=rt7-qmemNDk   \n",
       "196  [D] This is exactly the kind of misogyny that ...   \n",
       "197  [D] Hi everyone, check out my article here: ht...   \n",
       "198  Understanding differences between Drake’s old ...   \n",
       "199  [D] Is it worth signing up for interviewquery ...   \n",
       "\n",
       "                                              selftext  \n",
       "0                                                       \n",
       "1                                                       \n",
       "2                                                       \n",
       "3    I believe that artificial intelligence is the ...  \n",
       "4    A weapon to fight back\\n\\nElon musk and neural...  \n",
       "..                                                 ...  \n",
       "195                                          [removed]  \n",
       "196                                                     \n",
       "197  Hi everyone,\\n\\ncheck out my article here: [ht...  \n",
       "198                                          [removed]  \n",
       "199                                          [removed]  \n",
       "\n",
       "[200 rows x 4 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_ml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Intro NLP**\n",
    "\n",
    "\n",
    "Important Vocab:  \n",
    "**Tokenization** – process of converting a text into tokens  \n",
    "**Tokens** – words or entities present in the text  \n",
    "**Text object** – a sentence or a phrase or a word or an article  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the NLP Packages\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Text Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The entire process of cleaning and standardization of text, making it noise-free and ready for analysis is known as text preprocessing.  \n",
    "\n",
    "It is predominantly comprised of three steps:  \n",
    "\n",
    "Noise Removal  \n",
    "Lexicon Normalization  \n",
    "Object Standardization  \n",
    "\n",
    "### 2.1 Noise Removal  \n",
    "\n",
    "A general approach for noise removal is to prepare a dictionary of noisy entities, and iterate the text object by tokens (or by words), eliminating those tokens which are present in the noise dictionary.   \n",
    "\n",
    "Noisy words are for example: \n",
    "- language stopwords (commonly used words of a language – is, am, the, of, in etc), \n",
    "- URLs or links, \n",
    "- social media entities (mentions, hashtags), \n",
    "- punctuations\n",
    "- industry specific words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_ml['title'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Lexicon Normalization    \n",
    "\n",
    "Another type of textual noise is about the multiple representations exhibited by single word.  \n",
    "\n",
    "For example – “play”, “player”, “played”, “plays” and “playing” are the different variations of the word – “play”, Though they mean different but contextually all are similar. The step converts all the disparities of a word into their normalized form (also known as lemma).      \n",
    "  \n",
    "The most common lexicon normalization practices are :  \n",
    "- Stemming:  Stemming is a rudimentary rule-based process of stripping the suffixes (“ing”, “ly”, “es”, “s” etc) from a word.  \n",
    "- Lemmatization: Lemmatization, on the other hand, is an organized & step by step procedure of obtaining the root form of the word, it makes use of vocabulary (dictionary importance of words) and morphological analysis (word structure and grammar relations)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Object Standardization  \n",
    "Text data often contains words or phrases which are not present in any standard lexical dictionaries. These pieces are not recognized by search engines and models.  \n",
    "\n",
    "Some of the examples are – acronyms, hashtags with attached words, and colloquial slangs. With the help of regular expressions and manually prepared data dictionaries, this type of noise can be fixed, the code below uses a dictionary lookup method to replace social media slangs from a text.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Text to Features (Feature Engineering on text data)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **NLP Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing \"Documents\"\n",
    "\n",
    "Here are the sample documents combining together to form a corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = ai_ml[:50]\n",
    "testing_set = ai_ml[50:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 4)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# posterior = prior occurence X likelihood / evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OUR TIME is COMING! Have a Wonderful and Productive Day https://onpassive.pt/our-time-is-coming-have-a-wonderful-and-productive-day/?feed_id=14516&amp;_unique_id=5f38acc9b5bb2'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set['title'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-cfc2edd688e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNaiveBayesClassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/nltk/classify/naivebayes.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(cls, labeled_featuresets, estimator)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;31m# Count up how many times each feature value occurred, given\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;31m# the label and featurename.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mfeatureset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabeled_featuresets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m             \u001b[0mlabel_freqdist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatureset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(training_set['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classifier accuracy percent:\",(nltk.classify.accuracy(classifier, testing_set))*100)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
