{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Notebook Contents**\n",
    "\n",
    "- [Import Libraries](#importlibraries)  \n",
    "- [Import Dataframes](#importdataframes)\n",
    "- [Merge the Data](#mergedata)  \n",
    "- [Word Cleaning](#wordcleaning)\n",
    "- [Word EDA](#wordeda)\n",
    "- [Train/Test Split](#train/test/split)   \n",
    "- [Simple Logistic Regression](#simplelogreg) \n",
    "- [Gridsearched Count Vectorizer for Logistic Regression and Naive Bayes](#grcvlrnb)  \n",
    "- [Confusion Matrix](#cm)  \n",
    "- [Scores](#scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"importlibraries\"></a>\n",
    "## **Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aidancurley/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.feature_extraction.stop_words module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_extraction.text. Anything that cannot be imported from sklearn.feature_extraction.text is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from bs4 import BeautifulSoup       \n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction import stop_words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"importdataframes\"></a>\n",
    "## **Import Dataframes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ai = pd.read_csv('./data/data_ai.csv')\n",
    "data_ml = pd.read_csv('./data/data_ml.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>artificial</td>\n",
       "      <td>Could AI ethics draw on non-Western philosophi...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    subreddit                                              title selftext\n",
       "0  artificial  Could AI ethics draw on non-Western philosophi...      NaN"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ai.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>[R] Taming pretrained transformers for eXtreme...</td>\n",
       "      <td>New X-Transformer model from Amazon Research\\n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         subreddit                                              title  \\\n",
       "0  MachineLearning  [R] Taming pretrained transformers for eXtreme...   \n",
       "\n",
       "                                            selftext  \n",
       "0  New X-Transformer model from Amazon Research\\n...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ml.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the AI dataframe is (31299, 3)\n",
      "The shape of the ML dataframe is (31299, 3)\n"
     ]
    }
   ],
   "source": [
    "print(f'The shape of the AI dataframe is {data_ai.shape}')\n",
    "print(f'The shape of the ML dataframe is {data_ml.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"mergedata\"></a>\n",
    "## **Merge the Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_ai.append(data_ml).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='index',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the merged AI and ML dataframes are (62598, 3)\n"
     ]
    }
   ],
   "source": [
    "print(f'The shape of the merged AI and ML dataframes are {df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subreddit        0\n",
       "title            0\n",
       "selftext     31046\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's see what a title might look like:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Could AI ethics draw on non-Western philosophies to help reframe AI ethics'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['title'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's see what a selftext might look like:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I need to learn AI to make a project. Because of corona virus, our internal exams are probably not happening, so our teacher has decided to give high amount of marks to AI project.\\n\\nHow can I learn AI to build projects? I am saying university explicitly, because we have lots of other tasks to do in university as well, so please keep that in mind while suggesting me anything.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['selftext'][34]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"wordcleaning\"></a>\n",
    "## **Word Cleaning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subreddit        0\n",
       "title            0\n",
       "selftext     31046\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A lot of NaN values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the NaN values with ''\n",
    "df['selftext'].replace(np.nan, '', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subreddit    0\n",
       "title        0\n",
       "selftext     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>artificial</td>\n",
       "      <td>Could AI ethics draw on non-Western philosophi...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>artificial</td>\n",
       "      <td>Realistic simulation of tearing meat and peeli...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>artificial</td>\n",
       "      <td>[R] Using Deep RL to Model Human Locomotion Co...</td>\n",
       "      <td>In the new paper [*Deep Reinforcement Learning...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>artificial</td>\n",
       "      <td>Artificial Intelligence Easily Beats Human Fig...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>artificial</td>\n",
       "      <td>Foiling illicit cryptocurrency mining with art...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62593</th>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>What are some things that you wish you knew be...</td>\n",
       "      <td>[removed]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62594</th>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>[D] Does anyone created a formal database for ...</td>\n",
       "      <td>I'm looking for a database that has sufficient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62595</th>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>[P] Demo of \"Arbitrary Style Transfer with Sty...</td>\n",
       "      <td>Hi MachineLearning\\n\\nI'll introduce awsome st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62596</th>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>[R] Triplet loss for image retrieval</td>\n",
       "      <td>Hi, there!\\n\\n  \\nThis is an example of image ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62597</th>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>Telescopic Forks for Automated Warehouse AS/RS...</td>\n",
       "      <td>[removed]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62598 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             subreddit                                              title  \\\n",
       "0           artificial  Could AI ethics draw on non-Western philosophi...   \n",
       "1           artificial  Realistic simulation of tearing meat and peeli...   \n",
       "2           artificial  [R] Using Deep RL to Model Human Locomotion Co...   \n",
       "3           artificial  Artificial Intelligence Easily Beats Human Fig...   \n",
       "4           artificial  Foiling illicit cryptocurrency mining with art...   \n",
       "...                ...                                                ...   \n",
       "62593  MachineLearning  What are some things that you wish you knew be...   \n",
       "62594  MachineLearning  [D] Does anyone created a formal database for ...   \n",
       "62595  MachineLearning  [P] Demo of \"Arbitrary Style Transfer with Sty...   \n",
       "62596  MachineLearning               [R] Triplet loss for image retrieval   \n",
       "62597  MachineLearning  Telescopic Forks for Automated Warehouse AS/RS...   \n",
       "\n",
       "                                                selftext  \n",
       "0                                                         \n",
       "1                                                         \n",
       "2      In the new paper [*Deep Reinforcement Learning...  \n",
       "3                                                         \n",
       "4                                                         \n",
       "...                                                  ...  \n",
       "62593                                          [removed]  \n",
       "62594  I'm looking for a database that has sufficient...  \n",
       "62595  Hi MachineLearning\\n\\nI'll introduce awsome st...  \n",
       "62596  Hi, there!\\n\\n  \\nThis is an example of image ...  \n",
       "62597                                          [removed]  \n",
       "\n",
       "[62598 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's replace the [removed] and [deleted] with ''\n",
    "df['selftext'].replace('[removed]', '', inplace = True)\n",
    "df['selftext'].replace('[deleted]', '', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MachineLearning    31299\n",
       "artificial         31299\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the balance of the classes these are unbalanced\n",
    "df['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>artificial</td>\n",
       "      <td>Could AI ethics draw on non-Western philosophi...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>artificial</td>\n",
       "      <td>Realistic simulation of tearing meat and peeli...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>artificial</td>\n",
       "      <td>[R] Using Deep RL to Model Human Locomotion Co...</td>\n",
       "      <td>In the new paper [*Deep Reinforcement Learning...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>artificial</td>\n",
       "      <td>Artificial Intelligence Easily Beats Human Fig...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>artificial</td>\n",
       "      <td>Foiling illicit cryptocurrency mining with art...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62593</th>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>What are some things that you wish you knew be...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62594</th>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>[D] Does anyone created a formal database for ...</td>\n",
       "      <td>I'm looking for a database that has sufficient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62595</th>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>[P] Demo of \"Arbitrary Style Transfer with Sty...</td>\n",
       "      <td>Hi MachineLearning\\n\\nI'll introduce awsome st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62596</th>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>[R] Triplet loss for image retrieval</td>\n",
       "      <td>Hi, there!\\n\\n  \\nThis is an example of image ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62597</th>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>Telescopic Forks for Automated Warehouse AS/RS...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62598 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             subreddit                                              title  \\\n",
       "0           artificial  Could AI ethics draw on non-Western philosophi...   \n",
       "1           artificial  Realistic simulation of tearing meat and peeli...   \n",
       "2           artificial  [R] Using Deep RL to Model Human Locomotion Co...   \n",
       "3           artificial  Artificial Intelligence Easily Beats Human Fig...   \n",
       "4           artificial  Foiling illicit cryptocurrency mining with art...   \n",
       "...                ...                                                ...   \n",
       "62593  MachineLearning  What are some things that you wish you knew be...   \n",
       "62594  MachineLearning  [D] Does anyone created a formal database for ...   \n",
       "62595  MachineLearning  [P] Demo of \"Arbitrary Style Transfer with Sty...   \n",
       "62596  MachineLearning               [R] Triplet loss for image retrieval   \n",
       "62597  MachineLearning  Telescopic Forks for Automated Warehouse AS/RS...   \n",
       "\n",
       "                                                selftext  \n",
       "0                                                         \n",
       "1                                                         \n",
       "2      In the new paper [*Deep Reinforcement Learning...  \n",
       "3                                                         \n",
       "4                                                         \n",
       "...                                                  ...  \n",
       "62593                                                     \n",
       "62594  I'm looking for a database that has sufficient...  \n",
       "62595  Hi MachineLearning\\n\\nI'll introduce awsome st...  \n",
       "62596  Hi, there!\\n\\n  \\nThis is an example of image ...  \n",
       "62597                                                     \n",
       "\n",
       "[62598 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEXT CLEANING FUNCTION FOR EVERY POST IN BOTH SUBREDDITS TITLE + SELFTEXT\n",
    "\n",
    "# These will be replaced by a space ' ' \n",
    "symbol_replace_space = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "\n",
    "# We will get rid of all these in the function below\n",
    "bad_symbols = re.compile('[^0-9a-z #+_]')\n",
    "\n",
    "# We will get rid of all of the stopwords\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "\n",
    "    # Make all of the text lower case\n",
    "    text = text.lower() \n",
    "\n",
    "    # Replace symbol_replace_space with a space \n",
    "    text = symbol_replace_space.sub(' ', text)\n",
    "    \n",
    "    # Replace bad_symbols with a space\n",
    "    text = bad_symbols.sub('', text) \n",
    "    \n",
    "    # This gets rid of the integers\n",
    "    text = re.sub(r'\\d+', '', text) \n",
    "\n",
    "    # remove stopwords from text\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) \n",
    "\n",
    "    return text\n",
    "\n",
    "# Applying the clean_text function above to every title in df['title']\n",
    "df['title'] = df['title'].apply(clean_text)\n",
    "df['selftext'] = df['selftext'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>artificial</td>\n",
       "      <td>could ai ethics draw nonwestern philosophies h...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>artificial</td>\n",
       "      <td>realistic simulation tearing meat peeling chee...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>artificial</td>\n",
       "      <td>r using deep rl model human locomotion control...</td>\n",
       "      <td>new paper deep reinforcement learning modeling...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>artificial</td>\n",
       "      <td>artificial intelligence easily beats human fig...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>artificial</td>\n",
       "      <td>foiling illicit cryptocurrency mining artifici...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62593</th>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>things wish knew starting domain machine learning</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62594</th>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>anyone created formal database word meaning</td>\n",
       "      <td>im looking database sufficient information mat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62595</th>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>p demo arbitrary style transfer styleattention...</td>\n",
       "      <td>hi machinelearningill introduce awsome style t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62596</th>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>r triplet loss image retrieval</td>\n",
       "      <td>hi example image retrieval based mnist fashion...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62597</th>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>telescopic forks automated warehouse rs automa...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62598 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             subreddit                                              title  \\\n",
       "0           artificial  could ai ethics draw nonwestern philosophies h...   \n",
       "1           artificial  realistic simulation tearing meat peeling chee...   \n",
       "2           artificial  r using deep rl model human locomotion control...   \n",
       "3           artificial  artificial intelligence easily beats human fig...   \n",
       "4           artificial  foiling illicit cryptocurrency mining artifici...   \n",
       "...                ...                                                ...   \n",
       "62593  MachineLearning  things wish knew starting domain machine learning   \n",
       "62594  MachineLearning        anyone created formal database word meaning   \n",
       "62595  MachineLearning  p demo arbitrary style transfer styleattention...   \n",
       "62596  MachineLearning                     r triplet loss image retrieval   \n",
       "62597  MachineLearning  telescopic forks automated warehouse rs automa...   \n",
       "\n",
       "                                                selftext  \n",
       "0                                                         \n",
       "1                                                         \n",
       "2      new paper deep reinforcement learning modeling...  \n",
       "3                                                         \n",
       "4                                                         \n",
       "...                                                  ...  \n",
       "62593                                                     \n",
       "62594  im looking database sufficient information mat...  \n",
       "62595  hi machinelearningill introduce awsome style t...  \n",
       "62596  hi example image retrieval based mnist fashion...  \n",
       "62597                                                     \n",
       "\n",
       "[62598 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We need to concat the title and selftext so we can put it into one columns so we can count vectorize**\n",
    "- https://stackoverflow.com/questions/34710281/use-featureunion-in-scikit-learn-to-combine-two-pandas-columns-for-tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is how we created the new column in our dataframe\n",
    "df['title_selftext'] = df['title'] + ' ' + df['selftext']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>title_selftext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>artificial</td>\n",
       "      <td>could ai ethics draw nonwestern philosophies h...</td>\n",
       "      <td></td>\n",
       "      <td>could ai ethics draw nonwestern philosophies h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>artificial</td>\n",
       "      <td>realistic simulation tearing meat peeling chee...</td>\n",
       "      <td></td>\n",
       "      <td>realistic simulation tearing meat peeling chee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>artificial</td>\n",
       "      <td>r using deep rl model human locomotion control...</td>\n",
       "      <td>new paper deep reinforcement learning modeling...</td>\n",
       "      <td>r using deep rl model human locomotion control...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>artificial</td>\n",
       "      <td>artificial intelligence easily beats human fig...</td>\n",
       "      <td></td>\n",
       "      <td>artificial intelligence easily beats human fig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>artificial</td>\n",
       "      <td>foiling illicit cryptocurrency mining artifici...</td>\n",
       "      <td></td>\n",
       "      <td>foiling illicit cryptocurrency mining artifici...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    subreddit                                              title  \\\n",
       "0  artificial  could ai ethics draw nonwestern philosophies h...   \n",
       "1  artificial  realistic simulation tearing meat peeling chee...   \n",
       "2  artificial  r using deep rl model human locomotion control...   \n",
       "3  artificial  artificial intelligence easily beats human fig...   \n",
       "4  artificial  foiling illicit cryptocurrency mining artifici...   \n",
       "\n",
       "                                            selftext  \\\n",
       "0                                                      \n",
       "1                                                      \n",
       "2  new paper deep reinforcement learning modeling...   \n",
       "3                                                      \n",
       "4                                                      \n",
       "\n",
       "                                      title_selftext  \n",
       "0  could ai ethics draw nonwestern philosophies h...  \n",
       "1  realistic simulation tearing meat peeling chee...  \n",
       "2  r using deep rl model human locomotion control...  \n",
       "3  artificial intelligence easily beats human fig...  \n",
       "4  foiling illicit cryptocurrency mining artifici...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Train/Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['title_selftext']]\n",
    "y = df['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62598, 1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62598,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46948, 1)\n",
      "(15650, 1)\n",
      "(46948,)\n",
      "(15650,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MachineLearning    23474\n",
       "artificial         23474\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MachineLearning    7825\n",
       "artificial         7825\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Count Vectorizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the \"CountVectorizer\" object, which is scikit-learn's bag of words tool\n",
    "vectorizer = CountVectorizer(analyzer = \"word\",\n",
    "                             tokenizer = None,\n",
    "                             preprocessor = None,\n",
    "                             stop_words = None,\n",
    "                             max_features = 20000,\n",
    "                             min_df = 2\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit_transform() does two functions: First, it fits the model\n",
    "# and learns the vocabulary; second, it transforms our training data\n",
    "# into feature vectors. The input to fit_transform should be a list of \n",
    "# strings.\n",
    "\n",
    "train_data_features = vectorizer.fit_transform(X_train['title_selftext'])\n",
    "\n",
    "test_data_features = vectorizer.transform(X_test['title_selftext'])\n",
    "\n",
    "# Numpy arrays are easy to work with, so convert the result to an array.\n",
    "train_data_features = train_data_features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Simple Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the Logistic Regression\n",
    "lr = LogisticRegression(solver='liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(train_data_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8884723523898782"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(train_data_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8046645367412141"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(test_data_features, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression with Gridsearch training accuracy is: 0.8884723523898782\n",
      "LogisticRegression with Gridsearch testing accuracy is: 0.8046645367412141\n"
     ]
    }
   ],
   "source": [
    "print(f\"LogisticRegression with Gridsearch training accuracy is: {lr.score(train_data_features, y_train)}\")\n",
    "print(f\"LogisticRegression with Gridsearch testing accuracy is: {lr.score(test_data_features, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Gridsearched Count Vectorizer for Logistic Regression and Naive Bayes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline for CountVectorizer for Naive Bayes and Logisitc Regression\n",
    "pipe_cvec_lr = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('lr', LogisticRegression(solver='liblinear'))\n",
    "])\n",
    "\n",
    "pipe_cvec_nb = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('nb', MultinomialNB())    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_params = {\n",
    "    'cvec__max_features': [5000, 10_000, 15_000, 20_000, 25_000],\n",
    "    'cvec__min_df': [2, 3],\n",
    "    'cvec__ngram_range': [(1, 1), (1,2)],\n",
    "#     'cvec__max_df': [.90, .95]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate GridSearchCV.\n",
    "\n",
    "#LR\n",
    "gs_cvec_lr = GridSearchCV(pipe_cvec_lr, # what object are we optimizing?\n",
    "                  param_grid = pipe_params, # what parameters values are we searching?\n",
    "                  cv = 5) # 5-fold cross-validation.\n",
    "\n",
    "#NB\n",
    "gs_cvec_nb = GridSearchCV(pipe_cvec_nb, # what object are we optimizing?\n",
    "                  param_grid = pipe_params, # what parameters values are we searching?\n",
    "                  cv = 5) # 5-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aidancurley/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/aidancurley/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/aidancurley/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/aidancurley/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/aidancurley/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/aidancurley/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/aidancurley/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/aidancurley/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/aidancurley/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/aidancurley/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/aidancurley/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/aidancurley/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('cvec',\n",
       "                                        CountVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.int64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        preprocessor=None,\n",
       "                                                        stop_words=None,\n",
       "                                                        strip_accents=None,\n",
       "                                                        token_pattern='(?u)...\n",
       "                                                           n_jobs=None,\n",
       "                                                           penalty='l2',\n",
       "                                                           random_state=None,\n",
       "                                                           solver='liblinear',\n",
       "                                                           tol=0.0001,\n",
       "                                                           verbose=0,\n",
       "                                                           warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'cvec__max_features': [5000, 10000, 15000, 20000,\n",
       "                                                25000],\n",
       "                         'cvec__min_df': [2, 3],\n",
       "                         'cvec__ngram_range': [(1, 1), (1, 2)]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_cvec_lr.fit(X_train['title_selftext'], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('cvec',\n",
       "                                        CountVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.int64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        preprocessor=None,\n",
       "                                                        stop_words=None,\n",
       "                                                        strip_accents=None,\n",
       "                                                        token_pattern='(?u)...\\\\b',\n",
       "                                                        tokenizer=None,\n",
       "                                                        vocabulary=None)),\n",
       "                                       ('nb',\n",
       "                                        MultinomialNB(alpha=1.0,\n",
       "                                                      class_prior=None,\n",
       "                                                      fit_prior=True))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'cvec__max_features': [5000, 10000, 15000, 20000,\n",
       "                                                25000],\n",
       "                         'cvec__min_df': [2, 3],\n",
       "                         'cvec__ngram_range': [(1, 1), (1, 2)]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_cvec_nb.fit(X_test['title_selftext'], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvec__max_features': 25000, 'cvec__min_df': 2, 'cvec__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_cvec_lr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvec__max_features': 25000, 'cvec__min_df': 2, 'cvec__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_cvec_nb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression with Gridsearch training accuracy is: 0.9026795603646588\n",
      "LogisticRegression with Gridsearch testing accuracy is: 0.8090095846645368\n"
     ]
    }
   ],
   "source": [
    "# Score model train & test for Logisitic Regression\n",
    "print(f\"LogisticRegression with Gridsearch training accuracy is: {gs_cvec_lr.score(X_train['title_selftext'], y_train)}\")\n",
    "print(f\"LogisticRegression with Gridsearch testing accuracy is: {gs_cvec_lr.score(X_test['title_selftext'], y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes with Gridsearch training accuracy is: 0.7982451828548958\n",
      "Naive Bayes with Gridsearch training accuracy is: 0.810588772250114\n"
     ]
    }
   ],
   "source": [
    "# Score model on train & test for Naive Bayes\n",
    "print(f\"Naive Bayes with Gridsearch training accuracy is: {gs_cvec_nb.score(X_train['title_selftext'], y_train)}\")\n",
    "print(f\"Naive Bayes with Gridsearch training accuracy is: {gs_cvec_nb.score(X_test['title_selftext'], y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Scores**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression with Gridsearch training accuracy is: 0.8884723523898782  \n",
    "Logistic Regression with Gridsearch testing accuracy is: 0.8046645367412141  \n",
    "\n",
    "Logistic Regression with Gridsearch training accuracy is: 0.9026795603646588  \n",
    "Logistic Regression with Gridsearch testing accuracy is: 0.8090095846645368   \n",
    "\n",
    "Naive Bayes with Gridsearch training accuracy is: 0.7982451828548958  \n",
    "Naive Bayes with Gridsearch training accuracy is: 0.810588772250114  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
