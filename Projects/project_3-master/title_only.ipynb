{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from bs4 import BeautifulSoup       \n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Import Dataframes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ai = pd.read_csv('../project_3-master/data/data_ai.csv')\n",
    "data_ml = pd.read_csv('../project_3-master/data/data_ml.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>artificial</td>\n",
       "      <td>Could AI ethics draw on non-Western philosophi...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    subreddit                                              title selftext\n",
       "0  artificial  Could AI ethics draw on non-Western philosophi...      NaN"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ai.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>[R] Taming pretrained transformers for eXtreme...</td>\n",
       "      <td>New X-Transformer model from Amazon Research\\n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         subreddit                                              title  \\\n",
       "0  MachineLearning  [R] Taming pretrained transformers for eXtreme...   \n",
       "\n",
       "                                            selftext  \n",
       "0  New X-Transformer model from Amazon Research\\n...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ml.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Merge the Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_ai.append(data_ml).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='index',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>artificial</td>\n",
       "      <td>Could AI ethics draw on non-Western philosophi...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>artificial</td>\n",
       "      <td>Realistic simulation of tearing meat and peeli...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>artificial</td>\n",
       "      <td>[R] Using Deep RL to Model Human Locomotion Co...</td>\n",
       "      <td>In the new paper [*Deep Reinforcement Learning...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>artificial</td>\n",
       "      <td>Artificial Intelligence Easily Beats Human Fig...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>artificial</td>\n",
       "      <td>Foiling illicit cryptocurrency mining with art...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62593</th>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>What are some things that you wish you knew be...</td>\n",
       "      <td>[removed]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62594</th>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>[D] Does anyone created a formal database for ...</td>\n",
       "      <td>I'm looking for a database that has sufficient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62595</th>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>[P] Demo of \"Arbitrary Style Transfer with Sty...</td>\n",
       "      <td>Hi MachineLearning\\n\\nI'll introduce awsome st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62596</th>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>[R] Triplet loss for image retrieval</td>\n",
       "      <td>Hi, there!\\n\\n  \\nThis is an example of image ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62597</th>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>Telescopic Forks for Automated Warehouse AS/RS...</td>\n",
       "      <td>[removed]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62598 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             subreddit                                              title  \\\n",
       "0           artificial  Could AI ethics draw on non-Western philosophi...   \n",
       "1           artificial  Realistic simulation of tearing meat and peeli...   \n",
       "2           artificial  [R] Using Deep RL to Model Human Locomotion Co...   \n",
       "3           artificial  Artificial Intelligence Easily Beats Human Fig...   \n",
       "4           artificial  Foiling illicit cryptocurrency mining with art...   \n",
       "...                ...                                                ...   \n",
       "62593  MachineLearning  What are some things that you wish you knew be...   \n",
       "62594  MachineLearning  [D] Does anyone created a formal database for ...   \n",
       "62595  MachineLearning  [P] Demo of \"Arbitrary Style Transfer with Sty...   \n",
       "62596  MachineLearning               [R] Triplet loss for image retrieval   \n",
       "62597  MachineLearning  Telescopic Forks for Automated Warehouse AS/RS...   \n",
       "\n",
       "                                                selftext  \n",
       "0                                                    NaN  \n",
       "1                                                    NaN  \n",
       "2      In the new paper [*Deep Reinforcement Learning...  \n",
       "3                                                    NaN  \n",
       "4                                                    NaN  \n",
       "...                                                  ...  \n",
       "62593                                          [removed]  \n",
       "62594  I'm looking for a database that has sufficient...  \n",
       "62595  Hi MachineLearning\\n\\nI'll introduce awsome st...  \n",
       "62596  Hi, there!\\n\\n  \\nThis is an example of image ...  \n",
       "62597                                          [removed]  \n",
       "\n",
       "[62598 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subreddit        0\n",
       "title            0\n",
       "selftext     31046\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's see what a title might look like:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Could AI ethics draw on non-Western philosophies to help reframe AI ethics'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['title'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Train/Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['title']]\n",
    "y = df['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Could AI ethics draw on non-Western philosophi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title\n",
       "0  Could AI ethics draw on non-Western philosophi..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62598, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62598,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46948, 1)\n",
      "(15650, 1)\n",
      "(46948,)\n",
      "(15650,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2432         ESTADÍSTICA DESCRIPTIVA PARA LA INVESTIGACIÓN\n",
       "54386                         [R] OgmaNeo plays Atari Pong\n",
       "40950                       Great Review of Linear Algebra\n",
       "16495    Microsoft CEO Satya Nadella says Artificial In...\n",
       "57103    [D] What are the performance metrices of word ...\n",
       "                               ...                        \n",
       "518                        Here's an interesting AI Video!\n",
       "18857    How enhanced reality technologies contribute t...\n",
       "56723    What is the absolute latest and greatest resea...\n",
       "5392           Software for Building AI Assistant/ Chatbot\n",
       "9086     There's a magazine written by AI. It's a littl...\n",
       "Name: title, Length: 46948, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['title']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Function for Cleaning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_to_words(raw_review):\n",
    "    # Function to convert a raw review to a string of words\n",
    "    # The input is a single string (a raw movie review), and \n",
    "    # the output is a single string (a preprocessed movie review)\n",
    "    \n",
    "    # 1. Remove HTML.\n",
    "    review_text = raw_review\n",
    "    \n",
    "    # 2. Remove non-letters.\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", review_text)\n",
    "    \n",
    "    # 3. Convert to lower case, split into individual words.\n",
    "    words = letters_only.lower().split()\n",
    "    \n",
    "    # 4. In Python, searching a set is much faster than searching\n",
    "    # a list, so convert the stop words to a set.\n",
    "    stops = set(stopwords.words('english'))\n",
    "    \n",
    "    # 5. Remove stop words.\n",
    "    meaningful_words = [w for w in words if not w in stops]\n",
    "    \n",
    "    # 6. Join the words back into one string separated by space, \n",
    "    # and return the result.\n",
    "    return(\" \".join(meaningful_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 62598 titles.\n"
     ]
    }
   ],
   "source": [
    "# Get the number of reviews based on the dataframe size.\n",
    "total_titles = df.shape[0]\n",
    "print(f'There are {total_titles} titles.')\n",
    "\n",
    "# Initialize an empty list to hold the clean reviews.\n",
    "clean_train_titles = []\n",
    "clean_test_titles = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and parsing the training set for titles...\n",
      "Review 1000 of 62598.\n",
      "Review 2000 of 62598.\n",
      "Review 3000 of 62598.\n",
      "Review 4000 of 62598.\n",
      "Review 5000 of 62598.\n",
      "Review 6000 of 62598.\n",
      "Review 7000 of 62598.\n",
      "Review 8000 of 62598.\n",
      "Review 9000 of 62598.\n",
      "Review 10000 of 62598.\n",
      "Review 11000 of 62598.\n",
      "Review 12000 of 62598.\n",
      "Review 13000 of 62598.\n",
      "Review 14000 of 62598.\n",
      "Review 15000 of 62598.\n",
      "Review 16000 of 62598.\n",
      "Review 17000 of 62598.\n",
      "Review 18000 of 62598.\n",
      "Review 19000 of 62598.\n",
      "Review 20000 of 62598.\n",
      "Review 21000 of 62598.\n",
      "Review 22000 of 62598.\n",
      "Review 23000 of 62598.\n",
      "Review 24000 of 62598.\n",
      "Review 25000 of 62598.\n",
      "Review 26000 of 62598.\n",
      "Review 27000 of 62598.\n",
      "Review 28000 of 62598.\n",
      "Review 29000 of 62598.\n",
      "Review 30000 of 62598.\n",
      "Review 31000 of 62598.\n",
      "Review 32000 of 62598.\n",
      "Review 33000 of 62598.\n",
      "Review 34000 of 62598.\n",
      "Review 35000 of 62598.\n",
      "Review 36000 of 62598.\n",
      "Review 37000 of 62598.\n",
      "Review 38000 of 62598.\n",
      "Review 39000 of 62598.\n",
      "Review 40000 of 62598.\n",
      "Review 41000 of 62598.\n",
      "Review 42000 of 62598.\n",
      "Review 43000 of 62598.\n",
      "Review 44000 of 62598.\n",
      "Review 45000 of 62598.\n",
      "Review 46000 of 62598.\n",
      "Cleaning and parsing the testing set for titles...\n",
      "Review 47000 of 62598.\n",
      "Review 48000 of 62598.\n",
      "Review 49000 of 62598.\n",
      "Review 50000 of 62598.\n",
      "Review 51000 of 62598.\n",
      "Review 52000 of 62598.\n",
      "Review 53000 of 62598.\n",
      "Review 54000 of 62598.\n",
      "Review 55000 of 62598.\n",
      "Review 56000 of 62598.\n",
      "Review 57000 of 62598.\n",
      "Review 58000 of 62598.\n",
      "Review 59000 of 62598.\n",
      "Review 60000 of 62598.\n",
      "Review 61000 of 62598.\n",
      "Review 62000 of 62598.\n"
     ]
    }
   ],
   "source": [
    "print(\"Cleaning and parsing the training set for titles...\")\n",
    "\n",
    "j = 0\n",
    "\n",
    "for train_title in X_train['title']:\n",
    "    # Convert review to words, then append to clean_train_reviews.\n",
    "    clean_train_titles.append(review_to_words(train_title))\n",
    "    \n",
    "    # If the index is divisible by 1000, print a message\n",
    "    if (j + 1) % 1000 == 0:\n",
    "        print(f'Review {j + 1} of {total_titles}.')\n",
    "    \n",
    "    j += 1\n",
    "\n",
    "# Let's do the same for our testing set.\n",
    "\n",
    "print(\"Cleaning and parsing the testing set for titles...\")\n",
    "\n",
    "for test_title in X_test['title']:\n",
    "    # Convert review to words, then append to clean_train_reviews.\n",
    "    clean_test_titles.append(review_to_words(test_title))\n",
    "    \n",
    "    # If the index is divisible by 1000, print a message\n",
    "    if (j + 1) % 1000 == 0:\n",
    "        print(f'Review {j + 1} of {total_titles}.')\n",
    "        \n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46948"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_train_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15650"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_test_titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Word EDA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the \"CountVectorizer\" object, which is scikit-learn's bag of words tool\n",
    "vectorizer = CountVectorizer(analyzer = \"word\",\n",
    "                             tokenizer = None,\n",
    "                             preprocessor = None,\n",
    "                             stop_words = None,\n",
    "                             max_features = 2500,\n",
    "                             min_df=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit_transform() does two functions: First, it fits the model\n",
    "# and learns the vocabulary; second, it transforms our training data\n",
    "# into feature vectors. The input to fit_transform should be a list of \n",
    "# strings.\n",
    "\n",
    "train_data_features = vectorizer.fit_transform(clean_train_titles)\n",
    "\n",
    "test_data_features = vectorizer.transform(clean_test_titles)\n",
    "\n",
    "# Numpy arrays are easy to work with, so convert the result to an \n",
    "# array.\n",
    "train_data_features = train_data_features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = vectorizer.get_feature_names();    \n",
    "count_list = train_data_features.sum(axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict = dict(zip(word_list,count_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df = pd.DataFrame(train_data_features, columns= word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "counter = Counter()\n",
    "counter.update(word_dict)\n",
    "most_common = counter.most_common(15)\n",
    "most_df = pd.DataFrame(most_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ai</td>\n",
       "      <td>11655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>learning</td>\n",
       "      <td>7549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>machine</td>\n",
       "      <td>4904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>artificial</td>\n",
       "      <td>4685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>intelligence</td>\n",
       "      <td>4623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>data</td>\n",
       "      <td>2646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>using</td>\n",
       "      <td>1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>deep</td>\n",
       "      <td>1955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ml</td>\n",
       "      <td>1808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>new</td>\n",
       "      <td>1664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>neural</td>\n",
       "      <td>1661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>research</td>\n",
       "      <td>1272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>model</td>\n",
       "      <td>1249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>help</td>\n",
       "      <td>1207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>google</td>\n",
       "      <td>1142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0      1\n",
       "0             ai  11655\n",
       "1       learning   7549\n",
       "2        machine   4904\n",
       "3     artificial   4685\n",
       "4   intelligence   4623\n",
       "5           data   2646\n",
       "6          using   1991\n",
       "7           deep   1955\n",
       "8             ml   1808\n",
       "9            new   1664\n",
       "10        neural   1661\n",
       "11      research   1272\n",
       "12         model   1249\n",
       "13          help   1207\n",
       "14        google   1142"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46948, 2500)\n",
      "(15650, 2500)\n"
     ]
    }
   ],
   "source": [
    "print(train_data_features.shape)\n",
    "print(test_data_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_features[0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = vectorizer.get_feature_names()\n",
    "# print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Simple Logistic Regression without Gridsearch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import logistic regression.\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(solver = 'liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(train_data_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple LogisticRegression training accuracy is: 0.8259776774303484\n",
      "Simple LogisticRegression testing accuracy is: 0.7986581469648563\n"
     ]
    }
   ],
   "source": [
    "print(f\"Simple LogisticRegression training accuracy is: {lr.score(train_data_features, y_train)}\")\n",
    "print(f\"Simple LogisticRegression testing accuracy is: {lr.score(test_data_features, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Gridsearched Count Vectorizer for Logistic Regression and Naive Bayes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline for CountVectorizer for Naive Bayes and Logisitc Regression\n",
    "pipe_cvec_lr = Pipeline([\n",
    "    ('cvec', CountVectorizer(analyzer='word')),\n",
    "    ('lr', LogisticRegression(solver='liblinear'))\n",
    "])\n",
    "\n",
    "pipe_cvec_nb = Pipeline([\n",
    "    ('cvec', CountVectorizer(analyzer='word')),\n",
    "    ('nb', MultinomialNB())    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count Vectorizer Hyper Paramters\n",
    "pipe_params = {\n",
    "    'cvec__max_features': [5000, 10_000, 15_000, 20_000],\n",
    "    'cvec__min_df': [2, 3],\n",
    "    'cvec__ngram_range': [(1, 1), (1,2)],\n",
    "#     'cvec__max_df': [.90, .95]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate GridSearchCV.\n",
    "\n",
    "#LR\n",
    "gs_cvec_lr = GridSearchCV(pipe_cvec_lr, # what object are we optimizing?\n",
    "                  param_grid = pipe_params, # what parameters values are we searching?\n",
    "                  cv = 5) # 5-fold cross-validation.\n",
    "\n",
    "#NB\n",
    "gs_cvec_nb = GridSearchCV(pipe_cvec_nb, # what object are we optimizing?\n",
    "                  param_grid = pipe_params, # what parameters values are we searching?\n",
    "                  cv = 5) # 5-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('cvec',\n",
       "                                        CountVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.int64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        preprocessor=None,\n",
       "                                                        stop_words=None,\n",
       "                                                        strip_accents=None,\n",
       "                                                        token_pattern='(?u)...\n",
       "                                                           multi_class='auto',\n",
       "                                                           n_jobs=None,\n",
       "                                                           penalty='l2',\n",
       "                                                           random_state=None,\n",
       "                                                           solver='liblinear',\n",
       "                                                           tol=0.0001,\n",
       "                                                           verbose=0,\n",
       "                                                           warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'cvec__max_features': [5000, 10000, 15000, 20000],\n",
       "                         'cvec__min_df': [2, 3],\n",
       "                         'cvec__ngram_range': [(1, 1), (1, 2)]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_cvec_lr.fit(clean_train_titles, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('cvec',\n",
       "                                        CountVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.int64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        preprocessor=None,\n",
       "                                                        stop_words=None,\n",
       "                                                        strip_accents=None,\n",
       "                                                        token_pattern='(?u)...\\w\\\\w+\\\\b',\n",
       "                                                        tokenizer=None,\n",
       "                                                        vocabulary=None)),\n",
       "                                       ('nb',\n",
       "                                        MultinomialNB(alpha=1.0,\n",
       "                                                      class_prior=None,\n",
       "                                                      fit_prior=True))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'cvec__max_features': [5000, 10000, 15000, 20000],\n",
       "                         'cvec__min_df': [2, 3],\n",
       "                         'cvec__ngram_range': [(1, 1), (1, 2)]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_cvec_nb.fit(clean_train_titles, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvec__max_features': 5000, 'cvec__min_df': 2, 'cvec__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_cvec_lr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8095126907963696\n",
      "0.8126863795362007\n"
     ]
    }
   ],
   "source": [
    "print(gs_cvec_lr.best_score_)\n",
    "print(gs_cvec_nb.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression with Gridsearch training accuracy is: 0.8865127374968049\n",
      "LogisticRegression with Gridsearch testing accuracy is: 0.8090095846645368\n"
     ]
    }
   ],
   "source": [
    "# Score model train & test for Logisitic Regression\n",
    "print(f\"LogisticRegression with Gridsearch training accuracy is: {gs_cvec_lr.score(clean_train_titles, y_train)}\")\n",
    "print(f\"LogisticRegression with Gridsearch testing accuracy is: {gs_cvec_lr.score(clean_test_titles, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes with Gridsearch training accuracy is: 0.8427835051546392\n",
      "Naive Bayes with Gridsearch training accuracy is: 0.8133546325878594\n"
     ]
    }
   ],
   "source": [
    "# Score model on train & test for Naive Bayes\n",
    "print(f\"Naive Bayes with Gridsearch training accuracy is: {gs_cvec_nb.score(clean_train_titles, y_train)}\")\n",
    "print(f\"Naive Bayes with Gridsearch training accuracy is: {gs_cvec_nb.score(clean_test_titles, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Scores**\n",
    "\n",
    "Simple LogisticRegression training accuracy is: 0.8256694066899976  \n",
    "Simple LogisticRegression testing accuracy is: 0.8057296329453895  \n",
    "\n",
    "**Max_Features --> 2000, 3000, 4000, 5000:**   \n",
    "LogisticRegression with Gridsearch training accuracy is: 0.8475895933371314    \n",
    "LogisticRegression with Gridsearch testing accuracy is: 0.8102872955155855    \n",
    "\n",
    "\n",
    "Naive Bayes with Gridsearch training accuracy is: 0.816391307886384  \n",
    "Naive Bayes with Gridsearch training accuracy is: 0.8040205094815659  \n",
    "\n",
    "**Max_Features --> 5000, 10_000, 15_000, 20_000:**  \n",
    "LogisticRegression with Gridsearch training accuracy is: 0.8865127374968049  \n",
    "LogisticRegression with Gridsearch testing accuracy is: 0.8090095846645368  \n",
    "\n",
    "Naive Bayes with Gridsearch training accuracy is: 0.8427835051546392  \n",
    "Naive Bayes with Gridsearch training accuracy is: 0.8133546325878594  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
