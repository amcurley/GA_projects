{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Lab: Fun with Neural Nets\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a procedure for building a neural network to recognize handwritten digits.  The data is from [Kaggle](https://www.kaggle.com/c/digit-recognizer/data), and you will submit your results to Kaggle to test how well you did!\n",
    "\n",
    "1. Load the training data (`train.csv`) from [Kaggle](https://www.kaggle.com/c/digit-recognizer/data) (click on the link, be sure to sign in, then scroll down and on the left-hand side, click \"Download All\")\n",
    "2. Set up X and y (feature matrix and target vector)\n",
    "3. Split X and y into train and test subsets.\n",
    "4. Preprocess your data\n",
    "\n",
    "   - When dealing with image data, you need to normalize your `X` by dividing each value by the max value of a pixel (255).\n",
    "   - Since this is a multiclass classification problem, keras needs `y` to be a one-hot encoded matrix\n",
    "   \n",
    "5. Create your network.\n",
    "\n",
    "   - Remember that for multi-class classification you need a softamx activation function on the output layer.\n",
    "   - You may want to consider using regularization or dropout to improve performance.\n",
    "   \n",
    "6. Train your network.\n",
    "7. If you are unhappy with your model performance, try to tighten up your model by adding hidden layers, adding hidden layer units, changing the activation functions on the hidden layers, etc.\n",
    "8. Load in [Kaggle's](https://www.kaggle.com/c/digit-recognizer/data) `test.csv`\n",
    "9. Create your predictions (these should be numbers in the range 0-9).\n",
    "10. Save your predictions and submit them to Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "For this lab, you should complete the above sequence of steps for _at least_ two of the four \"configurations\":\n",
    "\n",
    "1. Using a `tensorflow` network (we did _not_ cover this in class!)\n",
    "2. Using a `keras` convolutional network\n",
    "3. Using a `keras` network with regularization\n",
    "4. Using a `tensorflow` convolutional network (we did _not_ cover this in class!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./digit-recognizer/train.csv')\n",
    "test = pd.read_csv(\"./digit-recognizer/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41996</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41997</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41998</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41999</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42000 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0          1       0       0       0       0       0       0       0       0   \n",
       "1          0       0       0       0       0       0       0       0       0   \n",
       "2          1       0       0       0       0       0       0       0       0   \n",
       "3          4       0       0       0       0       0       0       0       0   \n",
       "4          0       0       0       0       0       0       0       0       0   \n",
       "...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "41995      0       0       0       0       0       0       0       0       0   \n",
       "41996      1       0       0       0       0       0       0       0       0   \n",
       "41997      7       0       0       0       0       0       0       0       0   \n",
       "41998      6       0       0       0       0       0       0       0       0   \n",
       "41999      9       0       0       0       0       0       0       0       0   \n",
       "\n",
       "       pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0           0  ...         0         0         0         0         0   \n",
       "1           0  ...         0         0         0         0         0   \n",
       "2           0  ...         0         0         0         0         0   \n",
       "3           0  ...         0         0         0         0         0   \n",
       "4           0  ...         0         0         0         0         0   \n",
       "...       ...  ...       ...       ...       ...       ...       ...   \n",
       "41995       0  ...         0         0         0         0         0   \n",
       "41996       0  ...         0         0         0         0         0   \n",
       "41997       0  ...         0         0         0         0         0   \n",
       "41998       0  ...         0         0         0         0         0   \n",
       "41999       0  ...         0         0         0         0         0   \n",
       "\n",
       "       pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0             0         0         0         0         0  \n",
       "1             0         0         0         0         0  \n",
       "2             0         0         0         0         0  \n",
       "3             0         0         0         0         0  \n",
       "4             0         0         0         0         0  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "41995         0         0         0         0         0  \n",
       "41996         0         0         0         0         0  \n",
       "41997         0         0         0         0         0  \n",
       "41998         0         0         0         0         0  \n",
       "41999         0         0         0         0         0  \n",
       "\n",
       "[42000 rows x 785 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, y\n",
    "X = train.drop(columns='label') # Feature matrix\n",
    "y = train['label'] # Target vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 784)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Each row is an image\n",
    "# Each image is 28 x 28 so in total 784 pixels\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train, test, split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure each value is a float. (Otherwise, we get an error.)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# The current range of X_train and X_test is 0 to 255.\n",
    "# The code below is equivalent to X_train = X_train / 255.\n",
    "# This scales each value to be between 0 and 1.\n",
    "\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "test /= 255 #normalize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape\n",
    "X_train = X_train.values.reshape(-1,28,28,1)\n",
    "X_test = X_test.values.reshape(-1,28, 28, 1)\n",
    "test = test.values.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31500, 28, 28, 1)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check shape of full training data.\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change y_train.\n",
    "y_train = utils.to_categorical(y_train)\n",
    "y_test = utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Using a keras convolutional network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "124/124 [==============================] - 17s 134ms/step - loss: 0.5392 - accuracy: 0.8420 - val_loss: 0.1529 - val_accuracy: 0.9540\n",
      "Epoch 2/20\n",
      "124/124 [==============================] - 22s 180ms/step - loss: 0.1197 - accuracy: 0.9643 - val_loss: 0.1041 - val_accuracy: 0.9670\n",
      "Epoch 3/20\n",
      "124/124 [==============================] - 15s 118ms/step - loss: 0.0757 - accuracy: 0.9771 - val_loss: 0.1074 - val_accuracy: 0.9654\n",
      "Epoch 4/20\n",
      "124/124 [==============================] - 15s 123ms/step - loss: 0.0623 - accuracy: 0.9801 - val_loss: 0.0578 - val_accuracy: 0.9825\n",
      "Epoch 5/20\n",
      "124/124 [==============================] - 22s 177ms/step - loss: 0.0465 - accuracy: 0.9863 - val_loss: 0.0627 - val_accuracy: 0.9807\n",
      "Epoch 6/20\n",
      "124/124 [==============================] - 19s 150ms/step - loss: 0.0395 - accuracy: 0.9877 - val_loss: 0.0530 - val_accuracy: 0.9832\n",
      "Epoch 7/20\n",
      "124/124 [==============================] - 18s 145ms/step - loss: 0.0338 - accuracy: 0.9892 - val_loss: 0.0525 - val_accuracy: 0.9841\n",
      "Epoch 8/20\n",
      "124/124 [==============================] - 15s 117ms/step - loss: 0.0333 - accuracy: 0.9896 - val_loss: 0.0451 - val_accuracy: 0.9873\n",
      "Epoch 9/20\n",
      "124/124 [==============================] - 16s 131ms/step - loss: 0.0218 - accuracy: 0.9935 - val_loss: 0.0444 - val_accuracy: 0.9868\n",
      "Epoch 10/20\n",
      "124/124 [==============================] - 16s 130ms/step - loss: 0.0238 - accuracy: 0.9921 - val_loss: 0.0388 - val_accuracy: 0.9890\n",
      "Epoch 11/20\n",
      "124/124 [==============================] - 25s 202ms/step - loss: 0.0220 - accuracy: 0.9928 - val_loss: 0.0475 - val_accuracy: 0.9863\n",
      "Epoch 12/20\n",
      "124/124 [==============================] - 18s 147ms/step - loss: 0.0256 - accuracy: 0.9920 - val_loss: 0.0398 - val_accuracy: 0.9881\n",
      "Epoch 13/20\n",
      "124/124 [==============================] - 22s 177ms/step - loss: 0.0125 - accuracy: 0.9962 - val_loss: 0.0395 - val_accuracy: 0.9893\n",
      "Epoch 14/20\n",
      "124/124 [==============================] - 15s 120ms/step - loss: 0.0111 - accuracy: 0.9965 - val_loss: 0.0413 - val_accuracy: 0.9890\n",
      "Epoch 15/20\n",
      "124/124 [==============================] - 16s 125ms/step - loss: 0.0118 - accuracy: 0.9957 - val_loss: 0.0436 - val_accuracy: 0.9882\n",
      "Epoch 16/20\n",
      "124/124 [==============================] - 15s 121ms/step - loss: 0.0088 - accuracy: 0.9976 - val_loss: 0.0458 - val_accuracy: 0.9875\n",
      "Epoch 17/20\n",
      "124/124 [==============================] - 15s 121ms/step - loss: 0.0125 - accuracy: 0.9957 - val_loss: 0.0433 - val_accuracy: 0.9887\n",
      "Epoch 18/20\n",
      "124/124 [==============================] - 16s 125ms/step - loss: 0.0072 - accuracy: 0.9978 - val_loss: 0.0448 - val_accuracy: 0.9876\n",
      "Epoch 19/20\n",
      "124/124 [==============================] - 16s 128ms/step - loss: 0.0070 - accuracy: 0.9976 - val_loss: 0.0413 - val_accuracy: 0.9889\n",
      "Epoch 20/20\n",
      "124/124 [==============================] - 15s 123ms/step - loss: 0.0071 - accuracy: 0.9975 - val_loss: 0.0458 - val_accuracy: 0.9890\n"
     ]
    }
   ],
   "source": [
    "# 7. 0.98635\n",
    "\n",
    "# Instantiate the Model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters = 32, \n",
    "                kernel_size = (5,5), \n",
    "                activation = 'relu', \n",
    "                input_shape=(28, 28, 1)))\n",
    "\n",
    "model.add(MaxPooling2D\n",
    "             (pool_size=(2,2))) # dimensions of region of pooling\n",
    "model.add(Conv2D(filters = 32,\n",
    "                     kernel_size= (5,5),\n",
    "                     activation= 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train,\n",
    "                        y_train,\n",
    "                        batch_size=256,\n",
    "                        validation_data=(X_test, y_test),\n",
    "                        epochs=20,\n",
    "                        verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict results\n",
    "results = model.predict(test)\n",
    "\n",
    "# select the indix with the maximum probability\n",
    "results = np.argmax(results,axis = 1)\n",
    "\n",
    "results = pd.Series(results,name=\"Label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n",
    "\n",
    "submission.to_csv(\"submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Using a keras network with regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.8676 - accuracy: 0.7308 - val_loss: 0.3313 - val_accuracy: 0.9056\n",
      "Epoch 2/50\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.3802 - accuracy: 0.8888 - val_loss: 0.2482 - val_accuracy: 0.9279\n",
      "Epoch 3/50\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.3069 - accuracy: 0.9098 - val_loss: 0.2075 - val_accuracy: 0.9390\n",
      "Epoch 4/50\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2619 - accuracy: 0.9224 - val_loss: 0.1775 - val_accuracy: 0.9481\n",
      "Epoch 5/50\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.2325 - accuracy: 0.9311 - val_loss: 0.1615 - val_accuracy: 0.9537\n",
      "Epoch 6/50\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2079 - accuracy: 0.9376 - val_loss: 0.1497 - val_accuracy: 0.9559\n",
      "Epoch 7/50\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.1919 - accuracy: 0.9420 - val_loss: 0.1411 - val_accuracy: 0.9582\n",
      "Epoch 8/50\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.1833 - accuracy: 0.9442 - val_loss: 0.1332 - val_accuracy: 0.9611\n",
      "Epoch 9/50\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.1696 - accuracy: 0.9492 - val_loss: 0.1268 - val_accuracy: 0.9630\n",
      "Epoch 10/50\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.1604 - accuracy: 0.9499 - val_loss: 0.1225 - val_accuracy: 0.9650\n",
      "Epoch 11/50\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.1496 - accuracy: 0.9547 - val_loss: 0.1154 - val_accuracy: 0.9667\n",
      "Epoch 12/50\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.1468 - accuracy: 0.9546 - val_loss: 0.1102 - val_accuracy: 0.9683\n",
      "Epoch 13/50\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.1371 - accuracy: 0.9578 - val_loss: 0.1088 - val_accuracy: 0.9697\n",
      "Epoch 14/50\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.1318 - accuracy: 0.9577 - val_loss: 0.1062 - val_accuracy: 0.9698\n",
      "Epoch 15/50\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.1248 - accuracy: 0.9622 - val_loss: 0.1077 - val_accuracy: 0.9696\n",
      "Epoch 16/50\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.1245 - accuracy: 0.9604 - val_loss: 0.1038 - val_accuracy: 0.9707\n",
      "Epoch 17/50\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.1173 - accuracy: 0.9640 - val_loss: 0.1022 - val_accuracy: 0.9714\n",
      "Epoch 18/50\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.1084 - accuracy: 0.9650 - val_loss: 0.1041 - val_accuracy: 0.9706\n",
      "Epoch 19/50\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.1068 - accuracy: 0.9660 - val_loss: 0.0997 - val_accuracy: 0.9719\n",
      "Epoch 20/50\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.1079 - accuracy: 0.9669 - val_loss: 0.0991 - val_accuracy: 0.9719\n",
      "Epoch 21/50\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.1055 - accuracy: 0.9666 - val_loss: 0.1071 - val_accuracy: 0.9698\n",
      "Epoch 22/50\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.1061 - accuracy: 0.9653 - val_loss: 0.1015 - val_accuracy: 0.9720\n",
      "Epoch 23/50\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.0988 - accuracy: 0.9677 - val_loss: 0.0986 - val_accuracy: 0.9721\n",
      "Epoch 24/50\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0942 - accuracy: 0.9693 - val_loss: 0.0977 - val_accuracy: 0.9719\n",
      "Epoch 25/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0915 - accuracy: 0.9695 - val_loss: 0.1017 - val_accuracy: 0.9724\n",
      "Epoch 26/50\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.0960 - accuracy: 0.9691 - val_loss: 0.0988 - val_accuracy: 0.9720\n",
      "Epoch 27/50\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.0902 - accuracy: 0.9703 - val_loss: 0.0968 - val_accuracy: 0.9730\n",
      "Epoch 28/50\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0862 - accuracy: 0.9717 - val_loss: 0.1001 - val_accuracy: 0.9725\n",
      "Epoch 29/50\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0869 - accuracy: 0.9711 - val_loss: 0.0986 - val_accuracy: 0.9721\n",
      "Epoch 30/50\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.0823 - accuracy: 0.9726 - val_loss: 0.0996 - val_accuracy: 0.9731\n",
      "Epoch 00030: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Credit to David Lee for assistance\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(28, 28, 1))) # This is flattening our matrix into a vector.\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(.5))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "# Compile model.\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "# Fit model on training data.\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=1, mode='auto')\n",
    "history = model.fit(X_train,\n",
    "                    y_train, \n",
    "                    batch_size=256,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    epochs=50,\n",
    "                    verbose=1,\n",
    "                    callbacks= [early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submitting predictions from https://www.kaggle.com/yassineghouzam/introduction-to-cnn-keras-0-997-top-6\n",
    "# predict results\n",
    "results = model.predict(test)\n",
    "\n",
    "# select the indix with the maximum probability\n",
    "results = np.argmax(results,axis = 1)\n",
    "\n",
    "results = pd.Series(results,name=\"Label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n",
    "\n",
    "submission.to_csv(\"submission_1.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-dsi] *",
   "language": "python",
   "name": "conda-env-.conda-dsi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
